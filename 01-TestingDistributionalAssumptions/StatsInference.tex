

--------------------------------------------------------------------------------
P-values

A p-value does not tell us the probability that a hypothesis is true, nor does a significance level apply to any particular sample.



The p-value is a random variable that varies from sample to sample.


The precise meaning of the p-value


There is often confusion about the precise meaning of the probability computed in a significance test. The convention in hypothesis testing is that the null hypothesis (H0) is assumed to be true. 


The difference between the statistic computed in the sample and the parameter specified by H0 is computed and the probability of obtaining a difference this large or large is calculated. This probability value is the probability of obtaining data as extreme or more extreme than the current data (assuming H0 is true). 


It is not the probability of the null hypothesis itself. Thus, if the probability value is 0.005, this does not mean that the probability that the null hypothesis is true is .005. It means that the probability of obtaining data as different or more different from the null hypothesis as those obtained in the experiment is 0.005.


The inferential step to conclude that the null hypothesis is false goes as follows: The data (or data more extreme) are very unlikely given that the null hypothesis is true. 

This means that: (1) a very unlikely event occurred or (2) the null hypothesis is false. The inference usually made is that the null hypothesis is false. 


To illustrate that the probability is not the probability of the hypothesis, consider a test of a person who claims to be able to predict whether a coin will come up heads or tails. One should take a rather skeptical attitude toward this claim and require strong evidence to believe in its validity. 


The null hypothesis is that the person can predict correctly half the time (H0: Ï€ = 0.5). In the test, a coin is flipped 20 times and the person is correct 11 times. If the person has no special ability (H0 is true), then the probability of being correct 11 or more times out of 20 is 0.41. Would someone who was originally skeptical now believe that there is only a 0.41 chance that the null hypothesis is true? 


They almost certainly would not since they probably originally thought H0 had a very high probability of being true (perhaps as high as 0.9999). There is no logical reason for them to decrease their belief in the validity of the null hypothesis since the outcome was perfectly consistent with the null hypothesis. 


The proper interpretation of the test is as follows: A person made a rather extraordinary claim and should be able to provide strong evidence in support of the claim if the claim is to believed. The test provided data consistent with the null hypothesis that the person has no special ability since a person with no special ability would be able to predict as well or better more than 40% of the time. Therefore, there is no compelling reason to believe the extraordinary claim. However, the test does not prove the person cannot predict better than chance; it simply fails to provide evidence that he or she can. The probability that the null hypothesis is true is not determined by the statistical analysis conducted as part of hypothesis testing. Rather, the probability computed is the probability of obtaining data as different or more different from the null hypothesis (given that the null hypothesis is true) as the data actually obtained. 


%===================================================================================================%
%-------------------------------------------------------------------------------%
\newpage

Random Error

Random error is caused by any factors that randomly affect measurement of the variable across the sample. 
 
Statistical inference describe systems of procedures that can be used to draw conclusions from datasets arising from systems affected by random variation. The main types of procedures are confidence intervals and hypothesis tests. Hypothesis tests can be conducted by using considering the p-value, or comparing the test statistic and the critical value.
 
Despite the ubiquity of p-value tests, this particular test for statistical significance has come under heavy criticism due both to its inherent shortcomings and the potential for misinterpretation.

The p-value is the probability of obtaining a test statistic at least as extreme as the one that was actually observed,
assuming that the null hypothesis is true.
 
The lower the p-value, the less likely the result is if the null hypothesis is true, and consequently the more "significant" the result is, in the sense of statistical significance. One often accepts the alternative hypothesis, (i.e. rejects a null hypothesis) if the p-value is less than 0.05 or 0.01, corresponding respectively to a 5% or 1% chance of rejecting the null hypothesis when it is true (Type I error).
 
A small p-value that indicates statistical significance does not indicate that an alternative hypothesis is automatically correct; there are additional tests which may be performed in order to make a more definitive statement about the validity of the null hypothesis, such as some "goodness of fit" tests.
 
A hypothesis is a claim or statement about a property of definition.
 
A hypothesis test (or test of significance) is a standard procedure for testing a claim about a property of a population.
 
%===================================================================================================% 
Error Types
 
Type I and type II Error
 
Power of a test
 
To descrease both  and 
 %===================================================================================================%
 
Power of a hypothesis Test is the probability of rejecting a false null hypothesis
Confidence Intervals
 
Confidence interval
 
A confidence ellipse is a two dimensional
 
A confidence ellipsoid is a multidimensional
 
P-value
 %===================================================================================================%

Commonly used analyses
 
inference for a single proportion,
inference for a single mean,
inference for the difference between two proportions,
inference for the difference between two means;
 
 
The Paired t-test
The chi-squared test applied to contingency tables
The Anderson Darling Test of Normality
The Kolmogorov Smirnov test for distributions
The Grubb's Test for Outliers
 
 %===================================================================================================%
 
